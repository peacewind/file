## 学习资料汇总
- [quora How-do-I-learn-Apache-Spark](https://www.quora.com/How-do-I-learn-Apache-Spark/answer/Suman-Bharadwaj)
- [ColZer](https://github.com/ColZer/DigAndBuried)
- [JerryLead](https://github.com/JerryLead/SparkInternals)
- [zhangyi](https://zhangyi.gitbooks.io/spark-in-action/content/chapter2/sparkcontext.html)
- [0x0fff](https://0x0fff.com/category/spark/)
- [jerryshao](http://jerryshao.me/)


## 2 内存部分涉及的类
（注意：以下部分仅是李jiawei的个人理解，还没有得到证实）
### [1]
spark-2.1.0/common/unsafe/src/main/java/org/apache/spark/unsafe/Platform.java<br/>
（第137行）内存分配allocateMemory(size) 函数，它调用的是jdk中的函数。
<br/>
### [2]
在spark-2.1.0/common/unsafe/src/main/java/org/apache/spark/unsafe/memory目录有MemoryBlock.java和MemoryAllocator.java等多个类。它们会调用[1]中的函数。
<br/>
### [3]
spark-2.1.0/core/src/main/java/org/apache/spark/memory/TaskMemoryManager.java<br/>
也是个内存管理单元，在237行allocatePage()函数的262行调用了[2]中的HeapMemoryAllocator.java（或UnsafeMemoryAllocator.java），[2]又接着调用了[1]中的allocateMemory() 函数<br/>
（注意：HeapMemoryAllocator.java和UnsafeMemoryAllocator.java，它俩实现了同一个接口，根据不同的模式，会动态调用其中的一个）<br>
<br>
### [4]
spark-2.1.0/core/src/main/scala/org/apache/spark/storage/memory/MemoryStore.scala<br>
RDD的分区归它管（一个分区就是一个block）。里面的putXXX函数表示向内存写入数据。实际上就是给hashMap增加了一个键值对。<br>
### [5]
spark-2.1.0/core/src/main/scala/org/apache/spark/memory/*<br>
里面也有一些很有用的管理单元。<br>
MemoryManager.scala是一个抽象类。StaticMemoryManager.scala和UnifiedMemoryManager.scala继承了它。<br>
StaticMemoryManager.scala是spark 1.5及之前版本的传统的静态划分execution内存区域和storage内存区域的实现.<br>
UnifiedMemoryManager.scala是动态划分execution内存区域和storage内存区域的实现。<br>
注意：它们里面有acquireStorageMemory()和acquireExecutionMemory()函数，实际上这并不是真正申请内存的函数，它们只是在检查是不是有足够的空间来满足该申请。<br>
### [5]总结
感觉它的内存时这样管的：<br>
页表自己管：页表使用jdk中的allocateMemory()函数分配内存，自己管理。（参见上面的[1]、[2]、[3]）<br>
RDD归jvm管。创建memoryBlock的时候直接就是new LinkedHashMap[BlockId, MemoryEntry[_]]，然后往里面放block<br>
### [6]推荐书籍
- [Spark大数据处理：技术、应用与性能优化 (大数据技术丛书)](http://download.csdn.net/detail/nostandby/9804361)<br>
请注意书的以下几页：<br>
第91页：RDD在变换前后的新旧分区在物理上可能是同一块内存存储。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（是不是说它已经考虑到了重复数据的可能？？？？）<br>
第92页：RDD本质上是一个元数据结构，存储着元数据信息<br>
第138页：BlockManager管理RDD块<br>
第174页：spark存储系统全景图<br>
第179页：spark数据读写简要流程图<br>
第187页：MemoryStore内存块读写<br>
（书的代码版本比较老，只能做参考）
